# VeronaAI RAG Pipeline Architecture

## Overview
End-to-end retrieval-augmented generation system for querying venture capital portfolio documents, hosted on Vercel.

## Architecture Flow

### üì• Document Ingestion Pipeline
```
Raw Documents (PDFs, Word, etc.)
    ‚Üì
Contextual Chunking (preserves document structure & relationships)
    ‚Üì
Voyage AI Embeddings (voyage-large-3)
    - Optimized for financial/business documents
    - Superior contextual understanding for retrieval tasks
    ‚Üì
Weaviate Cloud Storage
    - Collections: VC_PE_Claude97_Optimized_Production
    - Stores: vectors + metadata (company_name, document_type, section_type)
```

### üîç Query Pipeline
```
User Query (Frontend - Next.js on Vercel)
    ‚Üì
API Route (/api/search-optimized)
    ‚Üì
Query Enhancement (Claude expands with relevant terms)
    Example: "portfolio companies" ‚Üí "portfolio companies private equity investment terms governance"
    ‚Üì
Query Embedding (Voyage AI voyage-large-3)
    ‚Üì
Hybrid Search in Weaviate
    ‚îú‚îÄ‚îÄ Vector Search (semantic similarity via cosine distance)
    ‚îî‚îÄ‚îÄ BM25 Search (keyword matching)
    ‚Üì
Result Merging & Scoring (top 20 chunks)
    ‚Üì
Document Grouping (by company_name, with deduplication)
    ‚Üì
Context Assembly (formatted chunks with metadata)
    ‚Üì
Answer Generation (Claude with structured prompts)
    - Confidence scoring (high/medium/low)
    - Source attribution
    - Company summaries
    ‚Üì
Streaming Response (via Vercel AI SDK)
```

## Tech Stack

| Layer | Technology | Purpose |
|-------|------------|---------|
| **Hosting** | Vercel | Frontend hosting, serverless API routes |
| **Frontend** | Next.js 14.2, TypeScript, Tailwind | React-based UI |
| **API** | Next.js API Routes | Serverless backend |
| **Embeddings** | Voyage AI (voyage-large-3) | Document & query vectorization |
| **Vector DB** | Weaviate Cloud | Hybrid search (vector + keyword) |
| **LLM** | Anthropic Claude Sonnet 4.5 | Query expansion & answer generation |
| **Monitoring** | Braintrust | Logging, tracing, quality metrics |

## Key Design Decisions

### Why Voyage AI?
- **Contextual embeddings**: Understands relationships between document chunks
- **Retrieval-optimized**: Specifically trained for search (not general-purpose)
- **Domain expertise**: Superior performance on financial/business documents
- **Late-interaction**: Better query-document matching

### Why Hybrid Search?
- **Vector search**: Captures semantic meaning and conceptual similarity
- **BM25 search**: Ensures exact term matches (company names, technical terms)
- **Best of both**: Balances semantic understanding with precision

### Performance Optimizations
- **Optimized collection**: Pre-processed for faster retrieval
- **Query caching**: 15-minute cache for repeated queries
- **Streaming responses**: Immediate user feedback via Vercel AI SDK
- **Parallel search**: Vector and BM25 run simultaneously

## Metrics & Monitoring
All operations tracked via Braintrust:
- Query latency
- Result relevance scores
- Answer confidence levels
- Source quality metrics
- End-to-end pipeline performance